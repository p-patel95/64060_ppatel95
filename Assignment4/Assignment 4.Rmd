---
title: "Assignment 4"
author: "Prerak Patel"
date: "3/18/2021"
output:
  html_document:
    df_print: paged
---
# Pharmaceuticals Industry
>An equities analyst is studying the pharmaceutical industry and would like your help in exploring and understanding the financial data collected by her firm. Her main objective is to understand the structure of the pharmaceutical industry using some basic financial measures. \n
Financial data gathered on 21 firms in the pharmaceutical industry are available in the file Pharmaceuticals.csv. For each firm, the following variables are recorded: \n


```{r setup, include=FALSE, warning=FALSE}
library(readr)
library(tidyverse)
library(data.table)
setwd("~/R_KSU/ML/Assignment4")
Ph.data <- read_csv("Pharmaceuticals.csv")
```

## Data Overview
```{r  warning=FALSE}
str(Ph.data)
```
> Kmeans clustering is only done with variables having continuous data. Hece variables - 'symbol', 'Name', 'Median_Recommendation', 'Location', 'Exchange' will be droped from further analytic steps

## Data cleaning
```{r  warning=FALSE}
summary(Ph.data)
```
Checking missing values
```{r  warning=FALSE}
colSums(is.na(Ph.data))
```

### Analyzing outliers for every variable before normalizing the variable, Outliers should not be taken for granted. As in our problem extreme points of some of the variables may be the triggers of a sell off or buy of a paticular stock, which if missed may lead to an unrecoveranle opportunity cost.
```{r  warning=FALSE}
#normalizing data to fit all variables in the same graph
# Scaling the data frame (z-score) 
data <- data.frame(scale(Ph.data[,3:11]))

boxplot(data, col=c("red","blue","green", "Orange","yellow", "Purple", "grey" ))
```

>> There are 8 outlier points over 9 variables of the pharmaceutical data. While selecting the optimized K value for implementing K-means algorithm. We will need to remove these outliered points before evaluating the optimized k value.

```{r  warning=FALSE}
library(factoextra)
v_name <- Ph.data[,1]
row.names(data) <- unlist(v_name) #Adding rownames from the original dataset as identifiers
distance <- get_dist(data,"euclidean")
fviz_dist(distance,
  order = TRUE,
  show_labels = TRUE,
  lab_size = NULL,
  gradient = list(low = "red", mid = "white", high = "blue"))
```

### Determining k 
>> Before determining k we will need a dataframe containing data without the outliers, because the Silhouette method and gap-static method is very sensitive with outliers, results may vary if the same evaulation is done with data contraining outliers. In my case the optimized K values without removing outliers came out as 4. Below is the case where Silhouette method & gap-static method is evaluated with data not having outliers.

```{r  warning=FALSE}
# Function to detect all outliers from the numerical variable data
an <- function(x){
q1 <- quantile(data[,x],0.25)
q3 <- quantile(data[,x],0.75)
iqr <- q3 -q1 
lower <- q1-1.5*iqr
upper <- q3+1.5*iqr
data[x][(data[x]<lower) | (data[x]>upper), ]
}


dummy <- vector('list',length = length(data))
for(i in seq_along(data)){
  dummy[[i]] <- an(names(data)[i])
}
names(dummy) <- names(data)

temp_data <- data %>% filter(Market_Cap != dummy[[1]], Beta != dummy[[2]], !(PE_Ratio %in% dummy[[3]]),
                ROE != dummy[[4]], !(Leverage %in% dummy[[6]]))
```

> List of all points from each variable resulting outliers are filtered out from the source data and saved into a temporary data; temp_data. Which is further used in the Elbow method, silhoute method and gap-static method to measure the optimized value of K

```{r  warning=FALSE}
library(factoextra)

# Elbow method
fviz_nbclust(temp_data, kmeans, method = "wss") +
  geom_vline(xintercept = 2, linetype = 2)+
  labs(subtitle = "Elbow method")

```

```{r  warning=FALSE}
# Silhouette method
fviz_nbclust(temp_data, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")
```

```{r  warning=FALSE}
set.seed(123)
fviz_nbclust(temp_data, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
  labs(subtitle = "Gap statistic method")
```
> We can conclude that the values of K can be 2 or 1. We will consider k-value to be 2 and continue with generating clusters with kmeans modelling technique. We will also execute the next steps with k=3. To understand the difference with the final output with an un-optimized K value.

```{r  warning=FALSE}
# lets start with k=3

ph.cluster3 <- kmeans(data, 3, 25)
ph.cluster3
```
```{r  warning=FALSE}
# Visualize the output of the ph.cluster3
result3 <- ph.cluster3$centers            # output the centers
result3
result3 <- as.data.frame(ph.cluster3$centers) %>%  mutate(clussters = as.factor(c(1,2,3)))
```
```{r  warning=FALSE}

ph.cluster3$size               # Number of companies in each cluster
```
```{r  warning=FALSE}
# Vizual Scatterplot for the ph.cluster3 clusters 
fviz_cluster(ph.cluster3, data, 
             palette = "Set2", ggtheme = theme_minimal(), geom = "text" )
```

```{r  warning=FALSE}
#  Now with k=2
ph.cluster2 <- kmeans(data, 2, 25)
ph.cluster2
```
```{r  warning=FALSE}
# Visualize the output
# output the centers, result2 will be further used to plot a parallel coordinate plot for analyzing the relation between the numeric variables and the cluster formed.
result2 <- ph.cluster2$centers       
result2                     
result2 <- as.data.frame(ph.cluster2$centers) %>% mutate(clusters = as.factor(c(1,2)))
```

```{r  warning=FALSE}
ph.cluster2$size               # Number of companies in each cluster in ph.cluster3
```

```{r  warning=FALSE}
ph.cluster2$cluster            # Identify the cluster of all observation
```
```{r  warning=FALSE}
cls <- data.frame(ph.cluster2$cluster)
clsdf <- setDT(cls, keep.rownames = TRUE)[]
colnames(clsdf) <- c("rn", "clusteN")
barplot(table(clsdf$clusteN), main="Cluster Distribution", xlab="ClusterNo", ylab="Cout")
```

```{r  warning=FALSE}
library(factoextra)

ph.cluster2$cluster

fviz_cluster(ph.cluster2, data, ellipse.type = "norm", geom = "text" ,
             palette = "Set2", ggtheme = theme_minimal())
```

```{r  warning=FALSE}
fviz_cluster(ph.cluster2, data, 
             palette = "Set2", ggtheme = theme_minimal(), geom = "text" )
```


```{r  warning=FALSE}
head(Ph.data)

datadf <- setDT(Ph.data, keep.rownames = TRUE)[]
#cl.data <- datadf %>% merge(datadf, clsdf, by="rn", all = TRUE)
cl.data <- cbind(datadf, clsdf)
result <- cl.data[,-c(1,16)]
result
```

> Concating the original dataframe with the clusterN column and saving it in the result dataframe. 

```{r  warning=FALSE}
#writing the result file, which I will be using to create a tableau dashboard for presenting the relation between non-numeric variables and the clusters formed with the k-means cluster model.
write_csv2(result,file="result.csv" )
```

```{r  warning=FALSE}
library(GGally)
ggparcoord(result2, columns = 1:9, groupColumn = 10)   # Parallel plots for k=2
```

## K=2;

> Cluster 1 ::>

>> Larger Cap Companies with stable prices as beta is low.

>> P/E ratio; more affordable then companies from cluster 2.

>> ROA & ROE; Percentage of return is lower, may be because they are large cap companies.

>> Turnover & Revenue growth; Larger cap companies tend to have a higher turnover but these values are in proportions to their market cap. Hence revenue growth is low and Profit Margin is high.

> Cluster 2 ::>

>> Smaller Cap companies with higher fluctuations in their prices as they have higher beta.

>> P/E ratio; Expensive companies, currently overpriced companies.

>> Most small cap companies may be start-ups and hences can give lower ROE, ROA & turnover, as they have lesser proportion of assets on hand and are expected to achieve breakthorughs in longer future rather than near future. Hence Revenue Growth can also be higher. But with a lower profit margin.


```{r  warning=FALSE}
# This how 3 cluster behaviour would look like. Which doesn't make a distinct difference and look more vague compared to the case with 2 cluster.
ggparcoord(result3, columns = 1:9, groupColumn = 10)  # Parallel plots for k=3
```

```{r  warning=FALSE}
# Tableau Dash Board for presenting the relation between clusters and Non-Numeric features of the dataset.
knitr::include_graphics('Assignment4_Dashboard_NonNumeric_vs_Cluster_relation.png')
```

> Considering k=2;

>> Cluster 1 can be called as *Big Coorporation Companies* that must be in existance since long time. Cluster 1 ==> *Giant Companies*

>> Cluster 2 may be start-up companies, which have been just listed recently on the exchange. Cluster 2 ==> *Regular sized Companies*.