---
title: "Cluster Analysis on Breakfast Cereal"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

# Problem Description

* In the following Unsupervised Learning activity, we try to cluster various types of breakfast cereal based on their nutritional content.


```{r warning=FALSE}
setwd("~/R_KSU/ML/Assignment5")
cereals_data <- read.csv("Cereals.csv", header=T)
data <- cereals_data
str(cereals_data)
```
```{r warning=FALSE}
summary(cereals_data)
```

```{r warning=FALSE}
head(cereals_data)
```

```{r warning=FALSE}
tail(cereals_data)
```

# Data Pre-Processing
```{r warning=FALSE}
# Total number of NA values in the data set
colSums(is.na(cereals_data))
```

```{r warning=FALSE}
# comment: There are 4 NA values in dataset we shall remove those. 
cereals_data <- na.omit(cereals_data)

#check for NA values again
colSums(is.na(cereals_data))
```


```{r warning=FALSE}
# Setting the rownames of the breakfast cereals to the row names, as this will later help us in visualizing the clusters.
data <- cereals_data
rownames(cereals_data) <- cereals_data$name
cereals_data$name = NULL
head(cereals_data)
```

```{r warning=FALSE}
## Converting categorical variables into dummy variables 
library(fastDummies)
cereals_data <- fastDummies::dummy_cols(cereals_data, select_columns = "mfr")[,-1]
cereals_data <- fastDummies::dummy_cols(cereals_data, select_columns = "type")[,-1]
cereals_data <- fastDummies::dummy_cols(cereals_data, select_columns = "shelf")[,-10]
str(cereals_data)
rownames(cereals_data) <- data$name
head(cereals_data)
```

# Data Normalization

```{r warning=FALSE}
## Data Scaling 
mean_norm_minmax <- function(x){
                                (x- mean(x)) /(max(x)-min(x))
}

cereals_data <- as.data.frame(lapply(cereals_data, mean_norm_minmax))
rownames(cereals_data) <- data$name
#cereals_data_norm <- scale(cereals_data_dum, center = T, scale = T)
head(cereals_data)
```

# DATA EXPLORATION

```{r, warning=FALSE, fig.width=12, fig.height=8, messages = FALSE}
# Correlation chart avoiding the dummified variables
library(factoextra)

distance <- get_dist(cereals_data[,2:13])
fviz_dist(distance, gradient = list(low= "#00AFBB", mid = "white", high = "#DC4E07"))
```

# Determining Optimal Clusters

```{r , warning=FALSE, fig.width=12, fig.height=8, messages = FALSE}
fviz_nbclust(cereals_data, FUN = hcut, method = "wss")
```

* From these estimators, lets assume the optimum K would be 2 We shall evaluate its stability later.

# Hierarchical Clustering
### I used the euclidean distance measure.

```{r warning=FALSE}
dist <- dist(cereals_data[,1:12], method="euclidean")
```

* hierarchical clustering using ward linkage method.
```{r , warning=FALSE, fig.width=13, fig.height=8, messages = FALSE}
hc_fit_wd <- hclust(dist, method="ward")
plot(hc_fit_wd)
```

```{r , warning=FALSE, fig.width=10, fig.height=8, messages = FALSE}
points_hc <- cutree(hc_fit_wd, k=2)
cereals_clusts_hc <- cbind(points_hc, cereals_data)

colnames(cereals_clusts_hc)[1] <- "cluster_hc"
head(cereals_clusts_hc)
```


```{r , warning=FALSE, fig.width=10, fig.height=8, messages = FALSE}
library(cluster)
plot(hc_fit_wd)
rect.hclust(hc_fit_wd, k = 2, border = "red")
```

#### Quality of clusters Created

    - The silhouette width/value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation)  [i.e., intra-cluster cohesion and inter-cluster separation]
    - Ranges from -1 to +1  
    - Values closer to 1 means higher quality of the cluster created 

```{r , warning=FALSE, fig.width=10, fig.height=8, messages = FALSE}
library(cluster)
dist = daisy(x = cereals_data, metric = "euclidean")
sil_value = silhouette(points_hc, dist = dist)
plot(sil_value)
```

* Try to find the optimal number of clusters where silhouette width would be maximum
```{r, warning=FALSE, fig.width=10, fig.height=4, messages = FALSE}
sil_value_hc = 0
for (i in 2:20) {
  points_hc <- cutree(hc_fit_wd, k = i)
  sil_value_hc[i] = mean(silhouette(points_hc, dist = dist)[,3])
}
plot(1:20, sil_value_hc, type = "b", xlab = "No: of Clusters", ylab = "Silhouette Width")
```

#### Cluster Stability

* Clusterboot function using library(fpc)

```{r}
library(fpc)
#Input the scaled cereals_data
hclust_stability = clusterboot(cereals_data, clustermethod=hclustCBI, method="ward.D2", k=2, count = FALSE)
hclust_stability
```

* Analyze the clustering results  

```{r}
clusters = hclust_stability$result$partition 

```

* What are the cluster stability values? Values > 0.85 denote very stable clusters. 0.6 - 0.75 means the clusters show some patterns but needs to be investigated further  

```{r}
#Cluster stability values
hclust_stability$bootmean 
```

* How many times the different clusters were dissolved  

```{r}
#Cluster dissolution rate. If maximum Jaccard coefficient < 0.5, that cluster is assumed to be dissolved. Below code shows the number of times each cluster was dissolved. The lower the value, the better.
hclust_stability$bootbrd 
```

```{r}
library(ggplot2)

ggplot(cereals_clusts_hc, aes(sugars, sodium, color=factor(cluster_hc))) + geom_point()
```


